{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Evaluaiton du modèle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Scheduler pour le learning rate\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "#Entrainement du modèle\n",
    "import torch.optim as optim\n",
    "\n",
    "#Visualisation des résultats\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#Fonction de perte\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_aug_lots_path = 'D:/ApprentissageMachineTPFinal/data/dog_dataset_aug_lots.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe pour charger le dataset aug lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe personnalisée pour charger les données\n",
    "class DogBreedDataset(Dataset):\n",
    "    def __init__(self, dataset_aug_lots_path, transform=None):\n",
    "        self.file_path = dataset_aug_lots_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Charger uniquement les dimensions\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            if \"images\" in f:\n",
    "                self.data_len = f[\"images\"].shape[0] # type: ignore\n",
    "            else:\n",
    "                raise KeyError(\"Dataset 'images' not found in the HDF5 file.\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            image = f[\"images\"][idx] / 255.0  # type: ignore # Normalisation\n",
    "            label = f[\"labels\"][idx] # type: ignore\n",
    "        \n",
    "        # Appliquer une transformation éventuelle\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Format PyTorch\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Initialisation des datasets\n",
    "dataset = DogBreedDataset(dataset_aug_lots_path)\n",
    "\n",
    "# Division en ensembles\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Création des DataLoaders\n",
    "train_loader = DataLoader(Subset(dataset, train_indices), batch_size=64######################################################################################################################, shuffle=True)\n",
    "val_loader = DataLoader(Subset(dataset, val_indices), batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(Subset(dataset, test_indices), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=120):\n",
    "        super(DogBreedCNN, self).__init__()\n",
    "\n",
    "        # Convolutional layers with BatchNorm and ReLU\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # Reduce spatial dimensions by half\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(f\"Shape after flattening: {x.shape}\")\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = DogBreedCNN(num_classes=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test manuel d'etape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model outputs shape: torch.Size([64, 120])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "outputs = model(images)\n",
    "print(f\"Model outputs shape: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([64, 3, 224, 224])\n",
      "Sample images shape: torch.Size([64, 3, 224, 224])\n",
      "Sample labels: tensor([ 53,  22,  33,  89, 106,  37,  83,  93,  34,  93,  59, 116,  51,  49,\n",
      "         68,  25,  76, 113,  83,  97, 115,  89,  59,  49,  27,   9,  37,  69,\n",
      "         67,  28,  46,  51,  36, 106,  69,  65,  13,  47,  48,   3,  56,  42,\n",
      "         33, 109,  37,   2,  75,  22,  37,  29,  34,  75,   1,  34,  65,  60,\n",
      "         42,  73,  60,  56,  24,  38,  70,  92])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Sample images shape: {images.shape}\")\n",
    "    print(f\"Sample labels: {labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.7126\n",
      "Epoch [2/10], Loss: 4.5312\n",
      "Epoch [3/10], Loss: 4.4475\n",
      "Epoch [4/10], Loss: 4.3937\n",
      "Epoch [5/10], Loss: 4.3564\n",
      "Epoch [6/10], Loss: 4.3339\n",
      "Epoch [7/10], Loss: 4.3083\n",
      "Epoch [8/10], Loss: 4.2917\n",
      "Epoch [9/10], Loss: 4.2748\n",
      "Epoch [10/10], Loss: 4.2667\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler=StepLR(optimizer,step_size=1,gamma=0.1)   \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       117\n",
      "           1       1.00      0.00      0.00        81\n",
      "           2       1.00      0.00      0.00       143\n",
      "           3       1.00      0.00      0.00       122\n",
      "           4       1.00      0.00      0.00       111\n",
      "           5       1.00      0.00      0.00       160\n",
      "           6       1.00      0.00      0.00        67\n",
      "           7       1.00      0.00      0.00       148\n",
      "           8       1.00      0.00      0.00       112\n",
      "           9       1.00      0.00      0.00       112\n",
      "          10       0.00      0.00      0.00       122\n",
      "          11       0.00      0.00      0.00       139\n",
      "          12       1.00      0.00      0.00        52\n",
      "          13       1.00      0.00      0.00       109\n",
      "          14       1.00      0.00      0.00        90\n",
      "          15       1.00      0.00      0.00       115\n",
      "          16       1.00      0.00      0.00       117\n",
      "          17       1.00      0.00      0.00        93\n",
      "          18       0.00      0.00      0.00       122\n",
      "          19       1.00      0.00      0.00        99\n",
      "          20       1.00      0.00      0.00       117\n",
      "          21       1.00      0.00      0.00       115\n",
      "          22       0.00      0.00      0.00       103\n",
      "          23       1.00      0.00      0.00       148\n",
      "          24       1.00      0.00      0.00        88\n",
      "          25       1.00      0.00      0.00       107\n",
      "          26       1.00      0.00      0.00       113\n",
      "          27       1.00      0.00      0.00       115\n",
      "          28       0.00      0.00      0.00       124\n",
      "          29       1.00      0.00      0.00       121\n",
      "          30       0.00      0.00      0.00       139\n",
      "          31       1.00      0.00      0.00       127\n",
      "          32       1.00      0.00      0.00       118\n",
      "          33       1.00      0.00      0.00       105\n",
      "          34       1.00      0.00      0.00       112\n",
      "          35       1.00      0.00      0.00        46\n",
      "          36       0.01      0.01      0.01       166\n",
      "          37       1.00      0.00      0.00       116\n",
      "          38       0.00      0.00      0.00       136\n",
      "          39       1.00      0.00      0.00        57\n",
      "          40       0.00      0.00      0.00       107\n",
      "          41       0.00      0.00      0.00       119\n",
      "          42       0.00      0.00      0.00       159\n",
      "          43       0.10      0.01      0.02       122\n",
      "          44       0.02      0.01      0.01       159\n",
      "          45       1.00      0.00      0.00        58\n",
      "          46       0.00      0.00      0.00        97\n",
      "          47       1.00      0.00      0.00       132\n",
      "          48       1.00      0.00      0.00       123\n",
      "          49       0.00      0.00      0.00       112\n",
      "          50       1.00      0.00      0.00       117\n",
      "          51       1.00      0.00      0.00       104\n",
      "          52       1.00      0.00      0.00       119\n",
      "          53       0.00      0.00      0.00       129\n",
      "          54       1.00      0.00      0.00       118\n",
      "          55       0.00      0.00      0.00       115\n",
      "          56       1.00      0.00      0.00       114\n",
      "          57       1.00      0.00      0.00       131\n",
      "          58       1.00      0.00      0.00       111\n",
      "          59       0.05      0.16      0.07        97\n",
      "          60       0.02      0.83      0.04       122\n",
      "          61       1.00      0.00      0.00       114\n",
      "          62       1.00      0.00      0.00       101\n",
      "          63       0.01      0.26      0.03       137\n",
      "          64       1.00      0.00      0.00       118\n",
      "          65       0.00      0.00      0.00        96\n",
      "          66       1.00      0.00      0.00       102\n",
      "          67       1.00      0.00      0.00       102\n",
      "          68       0.01      0.33      0.03       147\n",
      "          69       1.00      0.00      0.00       109\n",
      "          70       1.00      0.00      0.00       109\n",
      "          71       1.00      0.00      0.00       111\n",
      "          72       1.00      0.00      0.00       125\n",
      "          73       1.00      0.00      0.00       103\n",
      "          74       1.00      0.00      0.00        77\n",
      "          75       1.00      0.00      0.00       149\n",
      "          76       1.00      0.00      0.00       128\n",
      "          77       1.00      0.00      0.00       122\n",
      "          78       1.00      0.00      0.00        97\n",
      "          79       1.00      0.00      0.00       127\n",
      "          80       1.00      0.00      0.00       126\n",
      "          81       1.00      0.00      0.00        86\n",
      "          82       1.00      0.00      0.00       103\n",
      "          83       1.00      0.00      0.00        94\n",
      "          84       1.00      0.00      0.00       119\n",
      "          85       0.00      0.00      0.00       162\n",
      "          86       1.00      0.00      0.00       104\n",
      "          87       1.00      0.00      0.00        97\n",
      "          88       0.00      0.00      0.00       118\n",
      "          89       1.00      0.00      0.00       117\n",
      "          90       1.00      0.00      0.00        61\n",
      "          91       1.00      0.00      0.00        51\n",
      "          92       1.00      0.00      0.00        87\n",
      "          93       0.06      0.10      0.07       108\n",
      "          94       0.05      0.15      0.07       116\n",
      "          95       1.00      0.00      0.00       120\n",
      "          96       1.00      0.00      0.00        80\n",
      "          97       1.00      0.00      0.00        76\n",
      "          98       1.00      0.00      0.00       108\n",
      "          99       1.00      0.00      0.00        31\n",
      "         100       1.00      0.00      0.00        88\n",
      "         101       1.00      0.00      0.00       107\n",
      "         102       1.00      0.00      0.00       100\n",
      "         103       0.00      0.00      0.00       127\n",
      "         104       1.00      0.00      0.00        96\n",
      "         105       1.00      0.00      0.00       100\n",
      "         106       1.00      0.00      0.00       111\n",
      "         107       0.00      0.00      0.00       126\n",
      "         108       0.03      0.04      0.04       126\n",
      "         109       1.00      0.00      0.00       109\n",
      "         110       1.00      0.00      0.00        73\n",
      "         111       1.00      0.00      0.00       111\n",
      "         112       1.00      0.00      0.00       106\n",
      "         113       1.00      0.00      0.00        77\n",
      "         114       0.00      0.00      0.00       115\n",
      "         115       1.00      0.00      0.00        87\n",
      "         116       1.00      0.00      0.00       128\n",
      "         117       1.00      0.00      0.00        95\n",
      "         118       1.00      0.00      0.00       100\n",
      "         119       1.00      0.00      0.00       101\n",
      "\n",
      "    accuracy                           0.02     13190\n",
      "   macro avg       0.74      0.02      0.00     13190\n",
      "weighted avg       0.71      0.02      0.00     13190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# Rapport de classification\n",
    "print(classification_report(y_true, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=SummaryWriter()\n",
    "for epoch in range(num_epochs):\n",
    "    writer.add_scalar('Loss/train', running_loss, epoch)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
