{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Evaluaiton du modèle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Scheduler pour le learning rate\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "#Entrainement du modèle\n",
    "import torch.optim as optim\n",
    "\n",
    "#Visualisation des résultats\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#Fonction de perte\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_augmented_path = 'D:/ApprentissageMachineTPFinal/data/dog_dataset_aug_normal.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe pour charger le dataset aug**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe personnalisée pour charger les données\n",
    "class DogBreedDataset(Dataset):\n",
    "    def __init__(self, dataset_augmented_path, transform=None):\n",
    "        self.file_path = dataset_augmented_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Charger uniquement les dimensions\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            if \"images\" in f:\n",
    "                self.data_len = f[\"images\"].shape[0] # type: ignore\n",
    "            else:\n",
    "                raise KeyError(\"Dataset 'images' not found in the HDF5 file.\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            image = f[\"images\"][idx] / 255.0  # type: ignore # Normalisation\n",
    "            label = f[\"labels\"][idx] # type: ignore\n",
    "        \n",
    "        # Appliquer une transformation éventuelle\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Format PyTorch\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Initialisation des datasets\n",
    "dataset = DogBreedDataset(dataset_augmented_path)\n",
    "\n",
    "# Division en ensembles\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Création des DataLoaders\n",
    "train_loader = DataLoader(Subset(dataset, train_indices), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(Subset(dataset, val_indices), batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(Subset(dataset, test_indices), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creation du modele**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=120):\n",
    "        super(DogBreedCNN, self).__init__()\n",
    "\n",
    "        # Convolutional layers with BatchNorm and ReLU\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # Reduce spatial dimensions by half\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(f\"Shape after flattening: {x.shape}\")\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = DogBreedCNN(num_classes=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test manuel d'etape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images, labels = next(iter(train_loader))\n",
    "#outputs = model(images)\n",
    "#print(f\"Model outputs shape: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification le contenu des données dans le DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([64, 3, 224, 224])\n",
      "Sample images shape: torch.Size([64, 3, 224, 224])\n",
      "Sample labels: tensor([103,  65,  10,  73,  63,  93, 109, 109, 107,  30,  78,  67,   5,  63,\n",
      "        117,  17,  62, 101,  52,   5,  50,  74,  77,   6,  49,  37,  12,  48,\n",
      "         63, 106,  31, 119,   2,  42,  67,  60,  46,  69, 100,  86,  17,  31,\n",
      "         63,  42, 105,  23,  77, 114, 102,  30, 117, 111,  14,   4,   0, 106,\n",
      "          7,  71,   7,  91,  59,  72,  78,  88])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Sample images shape: {images.shape}\")\n",
    "    print(f\"Sample labels: {labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrainement aug**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 4.7771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ApprentissageMachineTPFinal\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Loss: 4.6818\n",
      "Epoch [3/30], Loss: 4.6025\n",
      "Epoch [4/30], Loss: 4.5374\n",
      "Epoch [5/30], Loss: 4.5050\n",
      "Epoch [6/30], Loss: 4.4617\n",
      "Epoch [7/30], Loss: 4.4470\n",
      "Epoch [8/30], Loss: 4.4215\n",
      "Epoch [9/30], Loss: 4.4051\n",
      "Epoch [10/30], Loss: 4.3722\n",
      "Epoch [11/30], Loss: 4.3552\n",
      "Epoch [12/30], Loss: 4.3379\n",
      "Epoch [13/30], Loss: 4.3158\n",
      "Epoch [14/30], Loss: 4.3028\n",
      "Epoch [15/30], Loss: 4.2804\n",
      "Epoch [16/30], Loss: 4.2515\n",
      "Epoch [17/30], Loss: 4.2206\n",
      "Epoch [18/30], Loss: 4.2075\n",
      "Epoch [19/30], Loss: 4.1876\n",
      "Epoch [20/30], Loss: 4.1753\n",
      "Epoch [21/30], Loss: 4.1554\n",
      "Epoch [22/30], Loss: 4.1529\n",
      "Epoch [23/30], Loss: 4.1348\n",
      "Epoch [24/30], Loss: 4.1198\n",
      "Epoch [25/30], Loss: 4.1119\n",
      "Epoch [26/30], Loss: 4.1087\n",
      "Epoch [27/30], Loss: 4.0871\n",
      "Epoch [28/30], Loss: 4.0843\n",
      "Epoch [29/30], Loss: 4.0644\n",
      "Epoch [30/30], Loss: 4.0549\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 30\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation du modele**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        62\n",
      "           1       1.00      0.00      0.00        27\n",
      "           2       0.03      0.02      0.02        51\n",
      "           3       0.00      0.00      0.00        54\n",
      "           4       1.00      0.00      0.00        56\n",
      "           5       0.05      0.30      0.09        54\n",
      "           6       1.00      0.00      0.00        22\n",
      "           7       0.12      0.17      0.14        70\n",
      "           8       0.06      0.26      0.09        47\n",
      "           9       0.09      0.06      0.08        47\n",
      "          10       0.00      0.00      0.00        49\n",
      "          11       0.03      0.12      0.05        49\n",
      "          12       1.00      0.00      0.00        20\n",
      "          13       1.00      0.00      0.00        60\n",
      "          14       1.00      0.00      0.00        38\n",
      "          15       0.00      0.00      0.00        46\n",
      "          16       0.00      0.00      0.00        51\n",
      "          17       1.00      0.00      0.00        39\n",
      "          18       1.00      0.00      0.00        60\n",
      "          19       0.00      0.00      0.00        37\n",
      "          20       0.06      0.04      0.05        51\n",
      "          21       1.00      0.00      0.00        42\n",
      "          22       0.00      0.00      0.00        46\n",
      "          23       0.10      0.78      0.18        60\n",
      "          24       1.00      0.00      0.00        32\n",
      "          25       0.00      0.00      0.00        39\n",
      "          26       0.00      0.00      0.00        35\n",
      "          27       0.00      0.00      0.00        35\n",
      "          28       0.17      0.07      0.10        45\n",
      "          29       1.00      0.00      0.00        46\n",
      "          30       0.07      0.06      0.06        54\n",
      "          31       0.00      0.00      0.00        56\n",
      "          32       0.00      0.00      0.00        54\n",
      "          33       0.06      0.30      0.10        37\n",
      "          34       0.06      0.29      0.09        52\n",
      "          35       1.00      0.00      0.00        20\n",
      "          36       0.07      0.02      0.03        60\n",
      "          37       0.00      0.00      0.00        47\n",
      "          38       0.17      0.10      0.12        52\n",
      "          39       1.00      0.00      0.00        27\n",
      "          40       0.00      0.00      0.00        54\n",
      "          41       1.00      0.00      0.00        53\n",
      "          42       0.00      0.00      0.00        53\n",
      "          43       1.00      0.00      0.00        53\n",
      "          44       0.13      0.51      0.21        65\n",
      "          45       1.00      0.00      0.00        27\n",
      "          46       0.00      0.00      0.00        49\n",
      "          47       0.00      0.00      0.00        44\n",
      "          48       0.02      0.02      0.02        49\n",
      "          49       0.04      0.18      0.07        39\n",
      "          50       1.00      0.00      0.00        40\n",
      "          51       1.00      0.00      0.00        38\n",
      "          52       0.07      0.17      0.09        48\n",
      "          53       0.06      0.11      0.08        44\n",
      "          54       0.00      0.00      0.00        45\n",
      "          55       0.19      0.34      0.25        44\n",
      "          56       0.05      0.41      0.09        37\n",
      "          57       0.03      0.02      0.02        64\n",
      "          58       1.00      0.00      0.00        37\n",
      "          59       0.04      0.03      0.03        40\n",
      "          60       0.02      0.03      0.02        39\n",
      "          61       1.00      0.00      0.00        60\n",
      "          62       1.00      0.00      0.00        44\n",
      "          63       0.07      0.05      0.06        64\n",
      "          64       0.12      0.02      0.03        59\n",
      "          65       0.00      0.00      0.00        49\n",
      "          66       0.04      0.02      0.03        46\n",
      "          67       0.00      0.00      0.00        31\n",
      "          68       0.04      0.02      0.03        50\n",
      "          69       0.00      0.00      0.00        57\n",
      "          70       1.00      0.00      0.00        57\n",
      "          71       1.00      0.00      0.00        48\n",
      "          72       1.00      0.00      0.00        42\n",
      "          73       0.00      0.00      0.00        35\n",
      "          74       1.00      0.00      0.00        27\n",
      "          75       0.05      0.58      0.09        48\n",
      "          76       0.08      0.08      0.08        50\n",
      "          77       0.06      0.03      0.04        58\n",
      "          78       0.00      0.00      0.00        32\n",
      "          79       0.08      0.19      0.11        53\n",
      "          80       0.05      0.07      0.06        43\n",
      "          81       1.00      0.00      0.00        39\n",
      "          82       0.17      0.02      0.04        43\n",
      "          83       1.00      0.00      0.00        35\n",
      "          84       1.00      0.00      0.00        44\n",
      "          85       0.03      0.03      0.03        60\n",
      "          86       0.00      0.00      0.00        41\n",
      "          87       0.03      0.05      0.04        37\n",
      "          88       0.00      0.00      0.00        40\n",
      "          89       0.00      0.00      0.00        35\n",
      "          90       1.00      0.00      0.00        21\n",
      "          91       1.00      0.00      0.00        18\n",
      "          92       1.00      0.00      0.00        41\n",
      "          93       0.07      0.25      0.10        32\n",
      "          94       0.10      0.02      0.04        45\n",
      "          95       0.00      0.00      0.00        45\n",
      "          96       1.00      0.00      0.00        36\n",
      "          97       1.00      0.00      0.00        33\n",
      "          98       0.00      0.00      0.00        46\n",
      "          99       1.00      0.00      0.00         3\n",
      "         100       1.00      0.00      0.00        33\n",
      "         101       0.09      0.02      0.04        44\n",
      "         102       0.00      0.00      0.00        37\n",
      "         103       0.08      0.19      0.11        52\n",
      "         104       1.00      0.00      0.00        35\n",
      "         105       1.00      0.00      0.00        51\n",
      "         106       1.00      0.00      0.00        36\n",
      "         107       0.04      0.20      0.07        55\n",
      "         108       0.00      0.00      0.00        50\n",
      "         109       0.00      0.00      0.00        40\n",
      "         110       1.00      0.00      0.00        36\n",
      "         111       0.00      0.00      0.00        37\n",
      "         112       1.00      0.00      0.00        43\n",
      "         113       1.00      0.00      0.00        27\n",
      "         114       0.00      0.00      0.00        38\n",
      "         115       1.00      0.00      0.00        39\n",
      "         116       0.07      0.23      0.11        52\n",
      "         117       0.35      0.11      0.16        56\n",
      "         118       0.00      0.00      0.00        42\n",
      "         119       1.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.06      5276\n",
      "   macro avg       0.39      0.05      0.03      5276\n",
      "weighted avg       0.34      0.06      0.03      5276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# Rapport de classification\n",
    "print(classification_report(y_true, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisez les Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss=0.0\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(num_epochs):\n",
    "    writer.add_scalar('Loss/train', running_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
