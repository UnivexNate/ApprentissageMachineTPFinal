{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Evaluaiton du modèle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Scheduler pour le learning rate\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "#Entrainement du modèle\n",
    "import torch.optim as optim\n",
    "\n",
    "#Visualisation des résultats\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#Fonction de perte\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_augmented_path = 'D:/ApprentissageMachineTPFinal/data/dog_dataset_aug_normal.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe pour charger le dataset aug**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe personnalisée pour charger les données\n",
    "class DogBreedDataset(Dataset):\n",
    "    def __init__(self, dataset_augmented_path, transform=None):\n",
    "        self.file_path = dataset_augmented_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Charger uniquement les dimensions\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            if \"images\" in f:\n",
    "                self.data_len = f[\"images\"].shape[0] # type: ignore\n",
    "            else:\n",
    "                raise KeyError(\"Dataset 'images' not found in the HDF5 file.\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            image = f[\"images\"][idx] / 255.0  # type: ignore # Normalisation\n",
    "            label = f[\"labels\"][idx] # type: ignore\n",
    "        \n",
    "        # Appliquer une transformation éventuelle\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Format PyTorch\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Initialisation des datasets\n",
    "dataset = DogBreedDataset(dataset_augmented_path)\n",
    "\n",
    "# Division en ensembles\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Création des DataLoaders\n",
    "train_loader = DataLoader(Subset(dataset, train_indices), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(Subset(dataset, val_indices), batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(Subset(dataset, test_indices), batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creation du modele**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=120):\n",
    "        super(DogBreedCNN, self).__init__()\n",
    "\n",
    "        # Convolutional layers with BatchNorm and ReLU\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)  # Reduce spatial dimensions by half\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(f\"Shape after flattening: {x.shape}\")\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = DogBreedCNN(num_classes=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test manuel d'etape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images, labels = next(iter(train_loader))\n",
    "#outputs = model(images)\n",
    "#print(f\"Model outputs shape: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification le contenu des données dans le DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([64, 3, 224, 224])\n",
      "Sample images shape: torch.Size([64, 3, 224, 224])\n",
      "Sample labels: tensor([ 37, 102, 100,  14,  46,  63,  19,  76,  96,   6,  19,  21,  64, 109,\n",
      "        114, 101,  59,  93,  87, 111,  33,   9,  14, 104,  40,   7,  52,  91,\n",
      "         32,  42,  54,  20, 110,   8, 118,  26,  10,  19,  68,  72,  75,  17,\n",
      "         54,  63,  39,  34,  10,  13,  33, 107,  67,  53,  75,  22,  56,  28,\n",
      "         34,  59,  62,  60,   8,  17,  57, 101])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Sample images shape: {images.shape}\")\n",
    "    print(f\"Sample labels: {labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrainement aug**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.7961\n",
      "Epoch [2/10], Loss: 4.6905\n",
      "Epoch [3/10], Loss: 4.5744\n",
      "Epoch [4/10], Loss: 4.4842\n",
      "Epoch [5/10], Loss: 4.4223\n",
      "Epoch [6/10], Loss: 4.3845\n",
      "Epoch [7/10], Loss: 4.3549\n",
      "Epoch [8/10], Loss: 4.3303\n",
      "Epoch [9/10], Loss: 4.3015\n",
      "Epoch [10/10], Loss: 4.2884\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 30\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation du modele**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.03      0.02        62\n",
      "           1       1.00      0.00      0.00        27\n",
      "           2       0.07      0.06      0.06        51\n",
      "           3       0.00      0.00      0.00        54\n",
      "           4       1.00      0.00      0.00        56\n",
      "           5       0.05      0.06      0.06        54\n",
      "           6       1.00      0.00      0.00        22\n",
      "           7       0.12      0.49      0.19        70\n",
      "           8       0.37      0.15      0.21        47\n",
      "           9       0.04      0.02      0.03        47\n",
      "          10       0.01      0.02      0.01        49\n",
      "          11       0.19      0.06      0.09        49\n",
      "          12       1.00      0.00      0.00        20\n",
      "          13       1.00      0.00      0.00        60\n",
      "          14       0.00      0.00      0.00        38\n",
      "          15       1.00      0.00      0.00        46\n",
      "          16       0.00      0.00      0.00        51\n",
      "          17       1.00      0.00      0.00        39\n",
      "          18       1.00      0.00      0.00        60\n",
      "          19       1.00      0.00      0.00        37\n",
      "          20       1.00      0.00      0.00        51\n",
      "          21       0.00      0.00      0.00        42\n",
      "          22       0.00      0.00      0.00        46\n",
      "          23       0.18      0.35      0.24        60\n",
      "          24       1.00      0.00      0.00        32\n",
      "          25       0.33      0.03      0.05        39\n",
      "          26       0.00      0.00      0.00        35\n",
      "          27       1.00      0.00      0.00        35\n",
      "          28       1.00      0.00      0.00        45\n",
      "          29       1.00      0.00      0.00        46\n",
      "          30       1.00      0.00      0.00        54\n",
      "          31       0.06      0.02      0.03        56\n",
      "          32       1.00      0.00      0.00        54\n",
      "          33       0.00      0.00      0.00        37\n",
      "          34       0.00      0.00      0.00        52\n",
      "          35       1.00      0.00      0.00        20\n",
      "          36       0.02      0.08      0.03        60\n",
      "          37       1.00      0.00      0.00        47\n",
      "          38       0.15      0.12      0.13        52\n",
      "          39       1.00      0.00      0.00        27\n",
      "          40       0.00      0.00      0.00        54\n",
      "          41       1.00      0.00      0.00        53\n",
      "          42       0.04      0.06      0.05        53\n",
      "          43       0.00      0.00      0.00        53\n",
      "          44       0.06      0.32      0.11        65\n",
      "          45       1.00      0.00      0.00        27\n",
      "          46       0.00      0.00      0.00        49\n",
      "          47       0.00      0.00      0.00        44\n",
      "          48       1.00      0.00      0.00        49\n",
      "          49       0.04      0.28      0.07        39\n",
      "          50       1.00      0.00      0.00        40\n",
      "          51       1.00      0.00      0.00        38\n",
      "          52       0.00      0.00      0.00        48\n",
      "          53       0.14      0.07      0.09        44\n",
      "          54       1.00      0.00      0.00        45\n",
      "          55       0.07      0.07      0.07        44\n",
      "          56       0.07      0.03      0.04        37\n",
      "          57       0.00      0.00      0.00        64\n",
      "          58       1.00      0.00      0.00        37\n",
      "          59       0.05      0.23      0.08        40\n",
      "          60       0.02      0.87      0.04        39\n",
      "          61       0.50      0.02      0.03        60\n",
      "          62       1.00      0.00      0.00        44\n",
      "          63       0.00      0.00      0.00        64\n",
      "          64       0.14      0.02      0.03        59\n",
      "          65       0.04      0.02      0.03        49\n",
      "          66       1.00      0.00      0.00        46\n",
      "          67       1.00      0.00      0.00        31\n",
      "          68       0.02      0.10      0.03        50\n",
      "          69       1.00      0.00      0.00        57\n",
      "          70       1.00      0.00      0.00        57\n",
      "          71       1.00      0.00      0.00        48\n",
      "          72       1.00      0.00      0.00        42\n",
      "          73       1.00      0.00      0.00        35\n",
      "          74       1.00      0.00      0.00        27\n",
      "          75       0.22      0.17      0.19        48\n",
      "          76       0.25      0.02      0.04        50\n",
      "          77       0.00      0.00      0.00        58\n",
      "          78       0.00      0.00      0.00        32\n",
      "          79       0.00      0.00      0.00        53\n",
      "          80       0.03      0.02      0.03        43\n",
      "          81       1.00      0.00      0.00        39\n",
      "          82       1.00      0.00      0.00        43\n",
      "          83       1.00      0.00      0.00        35\n",
      "          84       1.00      0.00      0.00        44\n",
      "          85       0.03      0.17      0.05        60\n",
      "          86       0.00      0.00      0.00        41\n",
      "          87       1.00      0.00      0.00        37\n",
      "          88       1.00      0.00      0.00        40\n",
      "          89       0.00      0.00      0.00        35\n",
      "          90       1.00      0.00      0.00        21\n",
      "          91       1.00      0.00      0.00        18\n",
      "          92       1.00      0.00      0.00        41\n",
      "          93       0.04      0.53      0.07        32\n",
      "          94       0.05      0.04      0.05        45\n",
      "          95       0.20      0.02      0.04        45\n",
      "          96       1.00      0.00      0.00        36\n",
      "          97       1.00      0.00      0.00        33\n",
      "          98       1.00      0.00      0.00        46\n",
      "          99       1.00      0.00      0.00         3\n",
      "         100       1.00      0.00      0.00        33\n",
      "         101       1.00      0.00      0.00        44\n",
      "         102       1.00      0.00      0.00        37\n",
      "         103       0.07      0.15      0.09        52\n",
      "         104       1.00      0.00      0.00        35\n",
      "         105       1.00      0.00      0.00        51\n",
      "         106       1.00      0.00      0.00        36\n",
      "         107       0.10      0.02      0.03        55\n",
      "         108       1.00      0.00      0.00        50\n",
      "         109       1.00      0.00      0.00        40\n",
      "         110       1.00      0.00      0.00        36\n",
      "         111       1.00      0.00      0.00        37\n",
      "         112       0.07      0.07      0.07        43\n",
      "         113       1.00      0.00      0.00        27\n",
      "         114       1.00      0.00      0.00        38\n",
      "         115       1.00      0.00      0.00        39\n",
      "         116       1.00      0.00      0.00        52\n",
      "         117       1.00      0.00      0.00        56\n",
      "         118       1.00      0.00      0.00        42\n",
      "         119       1.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.04      5276\n",
      "   macro avg       0.57      0.04      0.02      5276\n",
      "weighted avg       0.53      0.04      0.02      5276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# Rapport de classification\n",
    "print(classification_report(y_true, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisez les Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss=0.0\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(num_epochs):\n",
    "    writer.add_scalar('Loss/train', running_loss, epoch)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
