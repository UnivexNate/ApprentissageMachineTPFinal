{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import monitoring\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Division en ensembles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Création des DataLoaders\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "#Creation du modele\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Entrainement du modele et scheduler\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "#evaluation du modele\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#monitoring avec tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_simple_path = 'D:/Data/data/dog_dataset_no_aug.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classe pour charger le dataset no_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedDataset(Dataset):\n",
    "    def __init__(self, dataset_simple_path, transform=None):\n",
    "        self.file_path = dataset_simple_pat\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Charger uniquement les dimensions\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            if \"images\" in f:\n",
    "                self.data_len = f[\"images\"].shape[0] # type: ignore\n",
    "            else:\n",
    "                raise KeyError(\"Dataset 'images' not found in the HDF5 file.\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            image = f[\"images\"][idx] / 255.0  # type: ignore # Normalisation\n",
    "            label = f[\"labels\"][idx] # type: ignore\n",
    "        \n",
    "        # Appliquer une transformation éventuelle\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Format PyTorch\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Initialisation des datasets\n",
    "dataset = DogBreedDataset(dataset_simple_path)\n",
    "\n",
    "# Division en ensembles\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Création des DataLoaders\n",
    "train_loader = DataLoader(Subset(dataset, train_indices), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(Subset(dataset, val_indices), batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(Subset(dataset, test_indices), batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogBreedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=120):\n",
    "        super(DogBreedCNN, self).__init__()\n",
    "\n",
    "        # Couches de convolution\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "        # Pooling et dropout\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print(f\"Shape after conv1: {x.shape}\")\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(f\"Shape after conv2: {x.shape}\")\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        #print(f\"Shape after conv3: {x.shape}\")\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        #print(f\"Shape after conv4: {x.shape}\")\n",
    "\n",
    "\n",
    "        # Flatten the output\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(f\"Shape after flattening: {x.shape}\")\n",
    "\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = DogBreedCNN(num_classes=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model outputs shape: torch.Size([64, 120])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "outputs = model(images)\n",
    "print(f\"Model outputs shape: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement no aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([64, 3, 224, 224])\n",
      "Sample images shape: torch.Size([64, 3, 224, 224])\n",
      "Sample labels: tensor([ 57,  57, 107,  75,  42,  60,  81,  42, 116,  82,  65,  65,  95, 111,\n",
      "         65,  38,  85,  24,  98,  26, 100,  41,   5,  76,  96, 108,  28,   2,\n",
      "        116,  45,  30,   3,  54,  61,  85,  11, 107,  61, 107, 104,   3,  49,\n",
      "         97,  62,  74, 113,  27, 106, 116,  90,  73,  76,  21,   1,  56,  32,\n",
      "        117,  36,  60,  97,  62, 104, 107,  38])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Sample images shape: {images.shape}\")\n",
    "    print(f\"Sample labels: {labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.7834\n",
      "Learning Rate: 0.000100\n",
      "Epoch [2/10], Loss: 4.7764\n",
      "Learning Rate: 0.000100\n",
      "Epoch [3/10], Loss: 4.7747\n",
      "Learning Rate: 0.000100\n",
      "Epoch [4/10], Loss: 4.7719\n",
      "Learning Rate: 0.000100\n",
      "Epoch [5/10], Loss: 4.7706\n",
      "Learning Rate: 0.000010\n",
      "Epoch [6/10], Loss: 4.7701\n",
      "Learning Rate: 0.000010\n",
      "Epoch [7/10], Loss: 4.7700\n",
      "Learning Rate: 0.000010\n",
      "Epoch [8/10], Loss: 4.7684\n",
      "Learning Rate: 0.000010\n",
      "Epoch [9/10], Loss: 4.7689\n",
      "Learning Rate: 0.000010\n",
      "Epoch [10/10], Loss: 4.7697\n",
      "Learning Rate: 0.000001\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    print(f\"Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        38\n",
      "           1       1.00      0.00      0.00         9\n",
      "           2       1.00      0.00      0.00        28\n",
      "           3       1.00      0.00      0.00        33\n",
      "           4       1.00      0.00      0.00        24\n",
      "           5       1.00      0.00      0.00        24\n",
      "           6       1.00      0.00      0.00        12\n",
      "           7       1.00      0.00      0.00        27\n",
      "           8       1.00      0.00      0.00        30\n",
      "           9       1.00      0.00      0.00        12\n",
      "          10       1.00      0.00      0.00        34\n",
      "          11       1.00      0.00      0.00        28\n",
      "          12       1.00      0.00      0.00        11\n",
      "          13       1.00      0.00      0.00        22\n",
      "          14       1.00      0.00      0.00        20\n",
      "          15       1.00      0.00      0.00        21\n",
      "          16       1.00      0.00      0.00        19\n",
      "          17       1.00      0.00      0.00        16\n",
      "          18       1.00      0.00      0.00        22\n",
      "          19       1.00      0.00      0.00        13\n",
      "          20       1.00      0.00      0.00        14\n",
      "          21       1.00      0.00      0.00        22\n",
      "          22       1.00      0.00      0.00        22\n",
      "          23       1.00      0.00      0.00        32\n",
      "          24       1.00      0.00      0.00        17\n",
      "          25       1.00      0.00      0.00        20\n",
      "          26       1.00      0.00      0.00        26\n",
      "          27       1.00      0.00      0.00        24\n",
      "          28       1.00      0.00      0.00        25\n",
      "          29       1.00      0.00      0.00        18\n",
      "          30       1.00      0.00      0.00        21\n",
      "          31       1.00      0.00      0.00        30\n",
      "          32       1.00      0.00      0.00        21\n",
      "          33       1.00      0.00      0.00        24\n",
      "          34       1.00      0.00      0.00        22\n",
      "          35       1.00      0.00      0.00         7\n",
      "          36       1.00      0.00      0.00        24\n",
      "          37       1.00      0.00      0.00        19\n",
      "          38       1.00      0.00      0.00        17\n",
      "          39       1.00      0.00      0.00        10\n",
      "          40       1.00      0.00      0.00        23\n",
      "          41       1.00      0.00      0.00        23\n",
      "          42       1.00      0.00      0.00        35\n",
      "          43       1.00      0.00      0.00        30\n",
      "          44       1.00      0.00      0.00        41\n",
      "          45       1.00      0.00      0.00        15\n",
      "          46       1.00      0.00      0.00        25\n",
      "          47       1.00      0.00      0.00        28\n",
      "          48       1.00      0.00      0.00        28\n",
      "          49       1.00      0.00      0.00        21\n",
      "          50       1.00      0.00      0.00        23\n",
      "          51       1.00      0.00      0.00        15\n",
      "          52       1.00      0.00      0.00        21\n",
      "          53       1.00      0.00      0.00        17\n",
      "          54       1.00      0.00      0.00        22\n",
      "          55       1.00      0.00      0.00        22\n",
      "          56       1.00      0.00      0.00        28\n",
      "          57       1.00      0.00      0.00        25\n",
      "          58       1.00      0.00      0.00        16\n",
      "          59       1.00      0.00      0.00        24\n",
      "          60       1.00      0.00      0.00        21\n",
      "          61       1.00      0.00      0.00        20\n",
      "          62       1.00      0.00      0.00        21\n",
      "          63       0.01      1.00      0.02        26\n",
      "          64       1.00      0.00      0.00        22\n",
      "          65       1.00      0.00      0.00        22\n",
      "          66       1.00      0.00      0.00        18\n",
      "          67       1.00      0.00      0.00        19\n",
      "          68       1.00      0.00      0.00        35\n",
      "          69       1.00      0.00      0.00        21\n",
      "          70       1.00      0.00      0.00        19\n",
      "          71       1.00      0.00      0.00        26\n",
      "          72       1.00      0.00      0.00        25\n",
      "          73       1.00      0.00      0.00        24\n",
      "          74       1.00      0.00      0.00        19\n",
      "          75       1.00      0.00      0.00        27\n",
      "          76       1.00      0.00      0.00        13\n",
      "          77       1.00      0.00      0.00        31\n",
      "          78       1.00      0.00      0.00        23\n",
      "          79       1.00      0.00      0.00        31\n",
      "          80       1.00      0.00      0.00        17\n",
      "          81       1.00      0.00      0.00        17\n",
      "          82       1.00      0.00      0.00        23\n",
      "          83       1.00      0.00      0.00        24\n",
      "          84       1.00      0.00      0.00        26\n",
      "          85       1.00      0.00      0.00        24\n",
      "          86       1.00      0.00      0.00        15\n",
      "          87       1.00      0.00      0.00        19\n",
      "          88       1.00      0.00      0.00        30\n",
      "          89       1.00      0.00      0.00        24\n",
      "          90       1.00      0.00      0.00        13\n",
      "          91       1.00      0.00      0.00        13\n",
      "          92       1.00      0.00      0.00        21\n",
      "          93       1.00      0.00      0.00        21\n",
      "          94       1.00      0.00      0.00        21\n",
      "          95       1.00      0.00      0.00        30\n",
      "          96       1.00      0.00      0.00        13\n",
      "          97       1.00      0.00      0.00        12\n",
      "          98       1.00      0.00      0.00        18\n",
      "          99       1.00      0.00      0.00         7\n",
      "         100       1.00      0.00      0.00        18\n",
      "         101       1.00      0.00      0.00        23\n",
      "         102       1.00      0.00      0.00        25\n",
      "         103       1.00      0.00      0.00        29\n",
      "         104       1.00      0.00      0.00        24\n",
      "         105       1.00      0.00      0.00        20\n",
      "         106       1.00      0.00      0.00        21\n",
      "         107       1.00      0.00      0.00        28\n",
      "         108       1.00      0.00      0.00        30\n",
      "         109       1.00      0.00      0.00        23\n",
      "         110       1.00      0.00      0.00        15\n",
      "         111       1.00      0.00      0.00        21\n",
      "         112       1.00      0.00      0.00        21\n",
      "         113       1.00      0.00      0.00        12\n",
      "         114       1.00      0.00      0.00        24\n",
      "         115       1.00      0.00      0.00        15\n",
      "         116       1.00      0.00      0.00        24\n",
      "         117       1.00      0.00      0.00        27\n",
      "         118       1.00      0.00      0.00        26\n",
      "         119       1.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.01      2638\n",
      "   macro avg       0.99      0.01      0.00      2638\n",
      "weighted avg       0.99      0.01      0.00      2638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# Rapport de classification\n",
    "print(classification_report(y_true, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitoring avec TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.7682\n",
      "Epoch [2/10], Loss: 4.7704\n",
      "Epoch [3/10], Loss: 4.7699\n",
      "Epoch [4/10], Loss: 4.7688\n",
      "Epoch [5/10], Loss: 4.7688\n",
      "Epoch [6/10], Loss: 4.7688\n",
      "Epoch [7/10], Loss: 4.7677\n",
      "Epoch [8/10], Loss: 4.7694\n",
      "Epoch [9/10], Loss: 4.7685\n",
      "Epoch [10/10], Loss: 4.7675\n"
     ]
    }
   ],
   "source": [
    "# Initialisation de TensorBoard\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Ajouter la perte à TensorBoard\n",
    "    writer.add_scalar('Loss/train', running_loss/len(train_loader), epoch)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Lancer TensorBoard\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
