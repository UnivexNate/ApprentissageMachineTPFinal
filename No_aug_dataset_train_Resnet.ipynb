{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systèmes de fichiers et manipulations diverses\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch et modules associés\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Gestion des fichiers .h5\n",
    "import h5py\n",
    "\n",
    "# Division des ensembles (train/val/test) et calcul des métriques\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfo def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Redimensionner l'image à 224x224\n",
    "    transforms.ToTensor(),  # Convertir l'image en format [C, H, W] et normaliser entre 0 et 1\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation pour ResNet\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classe personnalisé pour le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogDataset(Dataset):\n",
    "    def __init__(self, h5_file_path, transform=None):\n",
    "        self.h5_file = h5py.File(h5_file_path, 'r')\n",
    "        self.images = self.h5_file['images']\n",
    "        self.labels = self.h5_file['labels'] \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.images[idx], dtype=torch.float16)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            image = image.permute(2, 0, 1)\n",
    "\n",
    "        if self.transform:\n",
    "            # Convertir temporairement l'image en float32 pour les transformations\n",
    "            image = image.float()\n",
    "            image = self.transform(image)\n",
    "            image = image.half() \n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classe de Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset\n",
    "h5_file_path = 'D:/ApprentissageMachineTPFinal/data/dog_dataset_no_aug.h5'\n",
    "dataset = DogDataset(h5_file_path)\n",
    "\n",
    "# Diviser en ensembles train/val/test\n",
    "indices = list(range(len(dataset_subset)))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Créer les DataLoaders\n",
    "train_loader = DataLoader(Subset(dataset_subset, train_indices), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(Subset(dataset_subset, val_indices), batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(Subset(dataset_subset, test_indices), batch_size=64, shuffle=False)\n",
    "\n",
    "# Filtrer uniquement les données des 3 classes (par exemple 0, 1, 2)\n",
    "class_indices = [i for i, label in enumerate(dataset.labels) if label in [0, 1, 2]]\n",
    "dataset_subset = Subset(dataset, class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger le modèle ResNet50 pré-entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 3)  # 3 classes\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction de perte et optimiseur, scheduler pour le learning rate et initialisation de l'early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhousset\\AppData\\Local\\Temp\\ipykernel_19340\\967691801.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesures de performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()  # Mettez le modèle en mode évaluation\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():  # Désactivez le calcul des gradients\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device, dtype=torch.float16)  # Convertir en float16\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)  # Passer les images au modèle\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    report = classification_report(all_labels, all_preds)\n",
    "    \n",
    "    return accuracy, f1, recall, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification des dimensions des images avant d'entrer dans le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boucle d’entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhousset\\AppData\\Local\\Temp\\ipykernel_19340\\2414848011.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5928\n",
      "Epoch [2/10], Loss: 1.4652\n",
      "Epoch [3/10], Loss: 1.2395\n",
      "Epoch [4/10], Loss: 1.1685\n",
      "Epoch [5/10], Loss: 0.7131\n",
      "Epoch [6/10], Loss: 1.2097\n",
      "Epoch [7/10], Loss: 0.8236\n",
      "Epoch [8/10], Loss: 0.3320\n",
      "Epoch [9/10], Loss: 0.1282\n",
      "Epoch [10/10], Loss: 0.0956\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, dtype=torch.float16)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Convertir en float32 avant de passer dans le modèle\n",
    "        images = images.to(torch.float32)\n",
    "\n",
    "        # Passage dans le modèle\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calcul de la perte\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Mettez à jour la perte\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping (marche pas, break caput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stopping(val_loss)\n",
    "#if early_stopping.early_stop:\n",
    "    #print(\"Early stopping triggered.\")\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhousset\\AppData\\Local\\Temp\\ipykernel_19340\\117625145.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9093\n"
     ]
    }
   ],
   "source": [
    "  # Validation\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device, dtype=torch.float16), labels.to(device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            \n",
    "            images = images.to(torch.float32)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "val_loss /= len(val_loader)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\\\n",
    "\n",
    "#Scheduler \n",
    "scheduler.step(val_loss)\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "torch.save(model.state_dict(), 'resnet50_best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation finale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3886, Validation Accuracy: 91.43%\n",
      "Test Results:\n",
      "Accuracy: 0.93, F1-Score: 0.93, Recall: 0.93\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        35\n",
      "           1       0.95      0.95      0.95        21\n",
      "           2       0.92      0.79      0.85        14\n",
      "\n",
      "    accuracy                           0.93        70\n",
      "   macro avg       0.93      0.90      0.91        70\n",
      "weighted avg       0.93      0.93      0.93        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device, dtype=torch.float16)  # Charger en float16\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        model = model.half()  # Charger le modèle en float16\n",
    "        outputs = model(images)  # Passer directement les images\n",
    "        loss = criterion(outputs.float(), labels)  # Convertir les sorties en float32 pour la perte\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_acc = 100 * correct / total\n",
    "print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "# Évaluation finale sur l'ensemble de test\n",
    "accuracy, f1, recall, report = evaluate_model(model, test_loader, device)\n",
    "print(\"Test Results:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}, F1-Score: {f1:.2f}, Recall: {recall:.2f}\")\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
