{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement dataset no aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "dataset_simple_path = 'D:/Data/data/dog_dataset_no_aug.h5'\n",
    "#dataset_augmented_path = 'D:/Data/data/dog_dataset_aug_normal.h5'\n",
    "#dataset_aug_lots_path = 'D:/Data/data/dog_dataset_aug_lots.h5'\n",
    "\n",
    "# Classe personnalisée pour charger les données\n",
    "class DogBreedDataset(Dataset):\n",
    "    def __init__(self, dataset_simple_path, transform=None):\n",
    "        self.file_path = dataset_simple_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Charger uniquement les dimensions\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            if \"images\" in f:\n",
    "                self.data_len = f[\"images\"].shape[0] # type: ignore\n",
    "            else:\n",
    "                raise KeyError(\"Dataset 'images' not found in the HDF5 file.\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            image = f[\"images\"][idx] / 255.0  # type: ignore # Normalisation\n",
    "            label = f[\"labels\"][idx] # type: ignore\n",
    "        \n",
    "        # Appliquer une transformation éventuelle\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Format PyTorch\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Initialisation des datasets\n",
    "dataset = DogBreedDataset(dataset_simple_path)\n",
    "\n",
    "# Division en ensembles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Création des DataLoaders\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_loader = DataLoader(Subset(dataset, train_indices), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(Subset(dataset, val_indices), batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(Subset(dataset, test_indices), batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement dataset aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "dataset_augmented_path = 'D:/ApprentissageMachineTPFinal/data/dog_dataset_aug_normal.h5'\n",
    "\n",
    "# Classe personnalisée pour charger les données\n",
    "class DogBreedDataset(Dataset):\n",
    "    def __init__(self, dataset_augmented_path, transform=None):\n",
    "        self.file_path = dataset_augmented_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Charger uniquement les dimensions\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            if \"images\" in f:\n",
    "                self.data_len = f[\"images\"].shape[0] # type: ignore\n",
    "            else:\n",
    "                raise KeyError(\"Dataset 'images' not found in the HDF5 file.\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            image = f[\"images\"][idx] / 255.0  # type: ignore # Normalisation\n",
    "            label = f[\"labels\"][idx] # type: ignore\n",
    "        \n",
    "        # Appliquer une transformation éventuelle\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Format PyTorch\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Initialisation des datasets\n",
    "dataset = DogBreedDataset(dataset_augmented_path)\n",
    "\n",
    "# Division en ensembles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Création des DataLoaders\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_loader = DataLoader(Subset(dataset, train_indices), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(Subset(dataset, val_indices), batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(Subset(dataset, test_indices), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement dataset lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "dataset_aug_lots_path = 'D:/ApprentissageMachineTPFinal/data/dog_dataset_aug_lots.h5'\n",
    "\n",
    "# Classe personnalisée pour charger les données\n",
    "class DogBreedDataset(Dataset):\n",
    "    def __init__(self, dataset_aug_lots_path, transform=None):\n",
    "        self.file_path = dataset_aug_lots_path\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Charger uniquement les dimensions\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            if \"images\" in f:\n",
    "                self.data_len = f[\"images\"].shape[0] # type: ignore\n",
    "            else:\n",
    "                raise KeyError(\"Dataset 'images' not found in the HDF5 file.\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.file_path, \"r\") as f:\n",
    "            image = f[\"images\"][idx] / 255.0  # type: ignore # Normalisation\n",
    "            label = f[\"labels\"][idx] # type: ignore\n",
    "        \n",
    "        # Appliquer une transformation éventuelle\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Format PyTorch\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Initialisation des datasets\n",
    "dataset = DogBreedDataset(dataset_aug_lots_path)\n",
    "\n",
    "# Division en ensembles\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Création des DataLoaders\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "train_loader = DataLoader(Subset(dataset, train_indices), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(Subset(dataset, val_indices), batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(Subset(dataset, test_indices), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Définition du modèle CNN\n",
    "class DogBreedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=120):  # 120 classes de races de chiens\n",
    "        super(DogBreedCNN, self).__init__()\n",
    "\n",
    "        # couches de convolution\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "        # Pooling et convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional layers with ReLU and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "\n",
    "        # Flatten the output\n",
    "        x = x.view(-1, 128 * 28 * 28)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Initialisation du modèle\n",
    "model = DogBreedCNN(num_classes=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement no aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 4.7823\n",
      "Epoch [2/25], Loss: 4.7702\n",
      "Epoch [3/25], Loss: 4.7689\n",
      "Epoch [4/25], Loss: 4.7681\n",
      "Epoch [5/25], Loss: 4.7674\n",
      "Epoch [6/25], Loss: 4.7676\n",
      "Epoch [7/25], Loss: 4.7669\n",
      "Epoch [8/25], Loss: 4.7666\n",
      "Epoch [9/25], Loss: 4.7660\n",
      "Epoch [10/25], Loss: 4.7660\n",
      "Epoch [11/25], Loss: 4.7666\n",
      "Epoch [12/25], Loss: 4.7665\n",
      "Epoch [13/25], Loss: 4.7666\n",
      "Epoch [14/25], Loss: 4.7661\n",
      "Epoch [15/25], Loss: 4.7662\n",
      "Epoch [16/25], Loss: 4.7665\n",
      "Epoch [17/25], Loss: 4.7664\n",
      "Epoch [18/25], Loss: 4.7662\n",
      "Epoch [19/25], Loss: 4.7657\n",
      "Epoch [20/25], Loss: 4.7658\n",
      "Epoch [21/25], Loss: 4.7657\n",
      "Epoch [22/25], Loss: 4.7656\n",
      "Epoch [23/25], Loss: 4.7658\n",
      "Epoch [24/25], Loss: 4.7655\n",
      "Epoch [25/25], Loss: 4.7656\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Configurations\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement lots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Configurations\n",
    "learning_rate = 0.001\n",
    "num_epochs = 25\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00        38\n",
      "           1       1.00      0.00      0.00         9\n",
      "           2       1.00      0.00      0.00        28\n",
      "           3       1.00      0.00      0.00        33\n",
      "           4       1.00      0.00      0.00        24\n",
      "           5       1.00      0.00      0.00        24\n",
      "           6       1.00      0.00      0.00        12\n",
      "           7       1.00      0.00      0.00        27\n",
      "           8       1.00      0.00      0.00        30\n",
      "           9       1.00      0.00      0.00        12\n",
      "          10       1.00      0.00      0.00        34\n",
      "          11       1.00      0.00      0.00        28\n",
      "          12       1.00      0.00      0.00        11\n",
      "          13       1.00      0.00      0.00        22\n",
      "          14       1.00      0.00      0.00        20\n",
      "          15       1.00      0.00      0.00        21\n",
      "          16       1.00      0.00      0.00        19\n",
      "          17       1.00      0.00      0.00        16\n",
      "          18       1.00      0.00      0.00        22\n",
      "          19       1.00      0.00      0.00        13\n",
      "          20       1.00      0.00      0.00        14\n",
      "          21       1.00      0.00      0.00        22\n",
      "          22       1.00      0.00      0.00        22\n",
      "          23       1.00      0.00      0.00        32\n",
      "          24       1.00      0.00      0.00        17\n",
      "          25       1.00      0.00      0.00        20\n",
      "          26       1.00      0.00      0.00        26\n",
      "          27       1.00      0.00      0.00        24\n",
      "          28       1.00      0.00      0.00        25\n",
      "          29       1.00      0.00      0.00        18\n",
      "          30       1.00      0.00      0.00        21\n",
      "          31       1.00      0.00      0.00        30\n",
      "          32       1.00      0.00      0.00        21\n",
      "          33       1.00      0.00      0.00        24\n",
      "          34       1.00      0.00      0.00        22\n",
      "          35       1.00      0.00      0.00         7\n",
      "          36       1.00      0.00      0.00        24\n",
      "          37       1.00      0.00      0.00        19\n",
      "          38       1.00      0.00      0.00        17\n",
      "          39       1.00      0.00      0.00        10\n",
      "          40       1.00      0.00      0.00        23\n",
      "          41       1.00      0.00      0.00        23\n",
      "          42       1.00      0.00      0.00        35\n",
      "          43       1.00      0.00      0.00        30\n",
      "          44       1.00      0.00      0.00        41\n",
      "          45       1.00      0.00      0.00        15\n",
      "          46       1.00      0.00      0.00        25\n",
      "          47       1.00      0.00      0.00        28\n",
      "          48       1.00      0.00      0.00        28\n",
      "          49       1.00      0.00      0.00        21\n",
      "          50       1.00      0.00      0.00        23\n",
      "          51       1.00      0.00      0.00        15\n",
      "          52       1.00      0.00      0.00        21\n",
      "          53       1.00      0.00      0.00        17\n",
      "          54       1.00      0.00      0.00        22\n",
      "          55       1.00      0.00      0.00        22\n",
      "          56       1.00      0.00      0.00        28\n",
      "          57       1.00      0.00      0.00        25\n",
      "          58       1.00      0.00      0.00        16\n",
      "          59       1.00      0.00      0.00        24\n",
      "          60       1.00      0.00      0.00        21\n",
      "          61       1.00      0.00      0.00        20\n",
      "          62       1.00      0.00      0.00        21\n",
      "          63       0.01      1.00      0.02        26\n",
      "          64       1.00      0.00      0.00        22\n",
      "          65       1.00      0.00      0.00        22\n",
      "          66       1.00      0.00      0.00        18\n",
      "          67       1.00      0.00      0.00        19\n",
      "          68       1.00      0.00      0.00        35\n",
      "          69       1.00      0.00      0.00        21\n",
      "          70       1.00      0.00      0.00        19\n",
      "          71       1.00      0.00      0.00        26\n",
      "          72       1.00      0.00      0.00        25\n",
      "          73       1.00      0.00      0.00        24\n",
      "          74       1.00      0.00      0.00        19\n",
      "          75       1.00      0.00      0.00        27\n",
      "          76       1.00      0.00      0.00        13\n",
      "          77       1.00      0.00      0.00        31\n",
      "          78       1.00      0.00      0.00        23\n",
      "          79       1.00      0.00      0.00        31\n",
      "          80       1.00      0.00      0.00        17\n",
      "          81       1.00      0.00      0.00        17\n",
      "          82       1.00      0.00      0.00        23\n",
      "          83       1.00      0.00      0.00        24\n",
      "          84       1.00      0.00      0.00        26\n",
      "          85       1.00      0.00      0.00        24\n",
      "          86       1.00      0.00      0.00        15\n",
      "          87       1.00      0.00      0.00        19\n",
      "          88       1.00      0.00      0.00        30\n",
      "          89       1.00      0.00      0.00        24\n",
      "          90       1.00      0.00      0.00        13\n",
      "          91       1.00      0.00      0.00        13\n",
      "          92       1.00      0.00      0.00        21\n",
      "          93       1.00      0.00      0.00        21\n",
      "          94       1.00      0.00      0.00        21\n",
      "          95       1.00      0.00      0.00        30\n",
      "          96       1.00      0.00      0.00        13\n",
      "          97       1.00      0.00      0.00        12\n",
      "          98       1.00      0.00      0.00        18\n",
      "          99       1.00      0.00      0.00         7\n",
      "         100       1.00      0.00      0.00        18\n",
      "         101       1.00      0.00      0.00        23\n",
      "         102       1.00      0.00      0.00        25\n",
      "         103       1.00      0.00      0.00        29\n",
      "         104       1.00      0.00      0.00        24\n",
      "         105       1.00      0.00      0.00        20\n",
      "         106       1.00      0.00      0.00        21\n",
      "         107       1.00      0.00      0.00        28\n",
      "         108       1.00      0.00      0.00        30\n",
      "         109       1.00      0.00      0.00        23\n",
      "         110       1.00      0.00      0.00        15\n",
      "         111       1.00      0.00      0.00        21\n",
      "         112       1.00      0.00      0.00        21\n",
      "         113       1.00      0.00      0.00        12\n",
      "         114       1.00      0.00      0.00        24\n",
      "         115       1.00      0.00      0.00        15\n",
      "         116       1.00      0.00      0.00        24\n",
      "         117       1.00      0.00      0.00        27\n",
      "         118       1.00      0.00      0.00        26\n",
      "         119       1.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.01      2638\n",
      "   macro avg       0.99      0.01      0.00      2638\n",
      "weighted avg       0.99      0.01      0.00      2638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluation\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# Rapport de classification\n",
    "print(classification_report(y_true, y_pred, zero_division=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
